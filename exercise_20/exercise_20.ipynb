{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "907e28aa-9d49-4c0b-9cb4-5e4acd3ccf47",
   "metadata": {},
   "source": [
    "# Exercise 20\n",
    "\n",
    "## Neuronale Netzwerke\n",
    "\n",
    "Viele Fortschritte im Bereich AI wurden durch neuronale Netzwerke erzielt. Ein einfaches neuronales Netzwerk hast du übrigens bereits gesehen, nämlich die lineare Regression! Ich zeige dir zuerst wie die lineare Regression mit der Pytorch library für neuronale Netzwerke funktioniert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685f74bb-454d-49c8-8444-00aec65b03b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# Diese Funktion erstellt Dummy Daten für unser Experiment\n",
    "def create_dummy_data(size=10000):\n",
    "    # Mit einm festen seed bekommen wir immer die gleichen \"zufälligen\" Daten\n",
    "    np.random.seed(42)\n",
    "    x = np.random.normal(size=size)\n",
    "    y = 2 + x + np.random.normal(size=size, scale=0.1)\n",
    "    \n",
    "    return np.resize(x, (size, 1)), np.resize(y, (size, 1))\n",
    "\n",
    "# Hier definieren wir nun das Modell in Pytorch\n",
    "class LinearRegressionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearRegressionModel, self).__init__()\n",
    "\n",
    "        # Hier definieren wir das \"neuronale Netzwerk\".\n",
    "        # Wir haben hier eine lineare Layer mit den Argumenten 1, 1.\n",
    "        # Das heisst wir haben einen Input und einen Output.\n",
    "        # Im Hintergrund multipliziert die Layer die Inputzahl mit einem Gewicht.\n",
    "        # Während dem Training lernt die Layer ihr Gewicht!\n",
    "        self.linear_layer = nn.Linear(1, 1)\n",
    "    \n",
    "    # Die forward Funktion beschreibt nun, wie wir aus dem Input den Output generieren\n",
    "    def forward(self, x):\n",
    "        return self.linear_layer(x)\n",
    "\n",
    "def linear_regression_with_pytorch():\n",
    "    x, y = create_dummy_data()\n",
    "    \n",
    "    # Hier wandeln wir die Daten in Tensoren um, dass ist einfach die Pytorch Version von Arrays :).\n",
    "    x, y = torch.FloatTensor(x), torch.FloatTensor(y)\n",
    "    \n",
    "    # Hier erstellen wir nun das Modell, welches wir oben definiert haben.\n",
    "    model = LinearRegressionModel()\n",
    "    \n",
    "    # Hier definieren wir den Loss, also den Fehler welchen wir minimieren möchten.\n",
    "    loss_function = nn.MSELoss()\n",
    "    \n",
    "    # Zusätzlich brauchen wir noch einen Optimizer.\n",
    "    # Dieser passt die Modellparameter an.\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # Nun beginnen wir mit dem Training, wir gehen in \"Epochen\" vor.\n",
    "    # In jeder Epoche trainieren wir einmal über die ganzen Trainingsdaten.\n",
    "    for epoch in range(1000):\n",
    "        # Hier setzten wir die Gradienten des Optimizers auf 0.\n",
    "        # Kannst du dich an eine Übung erinnern, in welcher wir Steigung einer Kurve berechnet haben um das Minimum zu finden :)?\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Wir berchnen nun die Vorhersage des neuronalen Netzwerks.\n",
    "        prediction = model.forward(x)\n",
    "        \n",
    "        # Hier schauen wir wie weit wir daneben lagen.\n",
    "        loss = loss_function(prediction, y)\n",
    "        \n",
    "        # Hier wird nun berechnet, wie wir die Modellparameter anpassen müssen, um den Loss kleiner zu machen.\n",
    "        loss.backward()\n",
    "        \n",
    "        # Hier passt der Optimizer unsere Parameter an.\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 100 == 0:\n",
    "            print(f'Wir sind in Epoche {epoch + 1}, der Loss ist {loss.item()} und die Modellparameter sind:')\n",
    "            print(dict(model.named_parameters()))\n",
    "\n",
    "linear_regression_with_pytorch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5f7f78e-4952-48fc-8fa4-f427335de193",
   "metadata": {},
   "source": [
    "### Aufgabe 1\n",
    "\n",
    "Kannst du diese Fragen beantworten?\n",
    "\n",
    "1. Betrachte zuerst `create_dummy_data`, verstehst du was für Daten diese Funktion generiert? Falls du willst kannst du einen Plot machen um es besser zu verstehen.\n",
    "2. Kannst du grob erklären, wie unser neuronales Netzwerk aufgebaut ist und was es macht? Vielleicht helfen dir die Kommentare, vielleicht auch einfach ein Youtube Video.\n",
    "3. Verstehst du den Output des Trainings? Was passiert mit dem Loss und den Parametern?\n",
    "4. Was denkst du, welche Methode verwendet Pytorch um den Loss zu minimieren? Du hast diese Methode auch schon kennengelernt.\n",
    "5. Verstehst du was die beiden Parameter `linear_layer.weight` und `linear_layer.bias` bedeuten?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f117f49-8054-41af-982c-4f61c6eecee5",
   "metadata": {},
   "source": [
    "### Aufgabe 2\n",
    "\n",
    "Eine der wichtigsten Eigenschaften eines neuronalen Netzwerks ist seine Architektur. Denn nur mit der richtigen Architektur kann das neuronale effektiv trainiert werden! Wir möchten nun untersuchen, wie die Architektur den Output des neuronalen Netzwerks beeinflusst. Ich gebe dir folgende Funktionen zur  Hilfe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c5936e-f19b-4055-b97a-eb4ca0ec5bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_neural_net_performance(Model, data='linear', data_size=1000, epochs=10):\n",
    "    def linear_func(x):\n",
    "        return 2 + x\n",
    "    \n",
    "    def nonlinear_func(x):\n",
    "        return [8 * (v - 0.5)**2 + 4 * v * np.sin(20 * v * v) for v in x]\n",
    "    \n",
    "    data_creation_func = linear_func if data == 'linear' else nonlinear_func\n",
    "\n",
    "    np.random.seed(42)\n",
    "    x = np.random.uniform(size=data_size)\n",
    "    y = data_creation_func(x) + np.random.normal(size=data_size, scale=0.05)\n",
    "    \n",
    "    x, y = torch.FloatTensor(np.resize(x, (data_size, 1))), torch.FloatTensor(np.resize(y, (data_size, 1)))\n",
    "\n",
    "    model = Model()\n",
    "    \n",
    "    loss_function = nn.MSELoss()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        prediction = model.forward(x)\n",
    "        loss = loss_function(prediction, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Final loss: {loss.item()}')\n",
    "\n",
    "    x_predict = torch.FloatTensor(np.reshape(np.linspace(0, 1, 100), (100, 1)))\n",
    "    prediction = model.forward(x_predict)\n",
    "    \n",
    "    plt.scatter(x, y, label= 'Training Data')\n",
    "    plt.plot(x_predict, prediction.detach().numpy().flatten(), c='r', label='Neural Net')\n",
    "    plt.plot(x_predict, data_creation_func(x_predict), c='g', label='Ground Truth')\n",
    "    plt.ylabel('y')\n",
    "    plt.xlabel('x')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cff5c9-52aa-4bdd-9d9b-b7598199ce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_neural_net_performance(LinearRegressionModel, data='linear', data_size=1000, epochs=10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8de429b-09b6-4372-8799-a03336f2d2b6",
   "metadata": {},
   "source": [
    "Untersuche nun, wie gut `LinearRegressionModel` mit `data='nonlinear'` funktioniert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b1017-9354-4ef1-85bc-953feb7701c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f4e496-04e9-4c61-a9c0-6e19430c0508",
   "metadata": {},
   "source": [
    "Was stellst du fest?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93210212-a11d-4fd9-b498-9bdcbb5bc05c",
   "metadata": {},
   "source": [
    "### Aufgabe 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92adc67a-15ed-494c-b080-372df87ffdd4",
   "metadata": {},
   "source": [
    "Hier ist nun ein Modell mit zwei Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c124e58-419b-4846-9981-9b49f82a85c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerModel, self).__init__()\n",
    "        \n",
    "        # Die \"mittlere\" Layer hat hier 2 Knoten!\n",
    "        # Wichtig ist nur, dass man mit 1 beginnt und mit 1 endet, denn wir haben 1-dimensionalen Input und Output.\n",
    "        self.linear_layer_1 = nn.Linear(1, 2)\n",
    "        self.linear_layer_2 = nn.Linear(2, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear_layer_1(x)\n",
    "        out = self.linear_layer_2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79dfaea9-8356-486e-a67a-6ab97d426252",
   "metadata": {},
   "source": [
    "Untersuche die Performance dieses Modells auf den linearen und nicht-linearen Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e6d1a3-6a00-4220-bc9b-6d4f8e7ac325",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d2a271-9aa0-4e32-aa83-34b1f9f73e7b",
   "metadata": {},
   "source": [
    "### Aufgabe 4\n",
    "\n",
    "Hier ist ein Modell mit einer zwei Layer und einer Aktivierung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c329ea-c054-44c8-9a9c-9965662b6121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TwoLayerWithActivationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TwoLayerWithActivationModel, self).__init__()\n",
    "        \n",
    "        self.linear_layer_1 = nn.Linear(1, 4)\n",
    "        self.linear_layer_2 = nn.Linear(4, 1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.linear_layer_1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear_layer_2(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "959a2d38-86c1-4aaa-a97a-e313cbc0cdbf",
   "metadata": {},
   "source": [
    "Untersuche die Performance diese Modells auf den linearen und nicht-linearen Daten. Findest du heraus, was die ReLu Funktion macht?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5780129d-e579-40bd-931b-78fed98dc5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c78382-e6b7-4cd8-b382-8bb92308cf12",
   "metadata": {},
   "source": [
    "### Aufgabe 5\n",
    "\n",
    "Erstelle nun ein Modell um auch die non-linearen Daten zu fitten. Du kannst sowohl mehr Layers hinzufügen, als auch die Layers breiter machen. Verwende zwischen den Layers jeweils ReLu. Tipp: Du musst dein Netzwerk zumindest ein bisschen tiefer (=mehr Layers), aber sehr viel breiter machen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4f408c-10df-4129-925e-9f1472dbd06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        \n",
    "        ...\n",
    "    \n",
    "    def forward(self, x):\n",
    "        ...\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc81bbb9-33e0-4680-b635-f62889fd0d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
